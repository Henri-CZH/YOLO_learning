{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26cb4e56",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>YOLO Segmentation</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfb8482",
   "metadata": {},
   "source": [
    "近年来，YOLO 系列在目标检测领域取得了显著成就，并进一步拓展到了目标分割领域，推出了 YOLO Segment 模型。这些模型不仅能够快速检测出图像中的目标，还能提供精确的分割掩码，帮助我们更好地理解目标的形状和边界。在本节课程中，我们将深入分析不同版本 YOLO 模型在分割任务中的异同，并通过可视化工具展示模型的输入输出结构，从而更好地理解其工作机制和性能表现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80865592",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>YOLO Segmentation 结构分析</center>\n",
    "<!-- \n",
    "&emsp;&emsp;Ultralytics OBB 模型的核心优势在于其能够处理旋转的边界框。与 Ultralytics Detect 模型相比，[Ultralytics OBB 模型的输出在每个边界框中多了一个表示旋转角度的参数](https://github.com/ultralytics/ultralytics/blob/v8.3.23/ultralytics/nn/modules/head.py#L217)。 -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f878e82",
   "metadata": {},
   "source": [
    "为了深入理解 YOLO Segmentation 模型的特性，我们首先需要对比不同版本 YOLO 模型在分割任务中的结构差异。以下是 YOLOv5、YOLOv7、YOLOv8、YOLOv9 和 YOLOv11 在分割任务中的结构分析，重点关注它们的输入输出格式以及分割掩码的生成方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b41044",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import netron\n",
    "from IPython.display import IFrame, display\n",
    "\n",
    "url, port = netron.start(\"./course_data/models/SEG/yolov5s-seg.onnx\", verbosity=0, browse=False)\n",
    "display(IFrame(f'http://{url}:{port}', width='100%', height='520px'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad772944",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "url, port = netron.start(\"./course_data/models/SEG/yolov7-seg.onnx\", verbosity=0, browse=False)\n",
    "display(IFrame(f'http://{url}:{port}', width='100%', height='520px'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59e0404",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "url, port = netron.start(\"./course_data/models/SEG/yolov8n-seg.onnx\", verbosity=0, browse=False)\n",
    "display(IFrame(f'http://{url}:{port}', width='100%', height='520px'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f85329",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "url, port = netron.start(\"./course_data/models/SEG/yolov9c-seg.onnx\", verbosity=0, browse=False)\n",
    "display(IFrame(f'http://{url}:{port}', width='100%', height='520px'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32448411",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "url, port = netron.start(\"./course_data/models/SEG/yolo11n-seg.onnx\", verbosity=0, browse=False)\n",
    "display(IFrame(f'http://{url}:{port}', width='100%', height='520px'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a69a095",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "与 YOLO Detection 模型类似，YOLO Segmentation 模型的输入节点同样接收一个包含 N 个样本的批次，每个样本是一张具有 3 个颜色通道、尺寸为高 × 宽像素的图像。不过，输出节点存在一些差异。YOLO Segmentation 模型**新增了一个维度为 `(batch, 32, w // 4, h // 4)` 的掩码原型图（Mask Prototypes）输出节点，并且在检测输出节点中额外增加了 32 个掩码系数，用于生成实例分割掩码。**\n",
    "\n",
    "具体来说，通过将掩码系数与掩码原型图进行加权求和，即可生成目标的实例分割掩码。其计算公式如下：\n",
    "\n",
    "$$\n",
    "\\text{mask} = \\sum_{i=1}^{32}(\\text{mask\\_coefficients}_{i} \\times \\text{mask\\_prototypes}_{i})\n",
    "$$\n",
    "\n",
    "在代码实现中，可以通过以下方式计算掩码：\n",
    "\n",
    "```python\n",
    "masks = torch.matmul(mask_coefficients, mask_prototypes)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff108da2",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "## <center>Ultralytics YOLO Segment 注册自定义插件</center>\n",
    "\n",
    "在 YOLO Detect 算法的变体中，通过集成 EfficientNMS 插件可以显著提高非极大值抑制（NMS）后处理的效率。然而，这个插件并不适用于 YOLO Segment 模型，因为 EfficientNMS 插件主要用于目标检测任务，其输出不包含实例分割所需的掩码系数，而实例分割需要通过掩码系数与掩码原型图结合来生成分割掩码。\n",
    "\n",
    "\n",
    "为了解决这些问题，在之前的章节中我们开发了一个名为 EfficientIdxNMS 的自定义插件。相较于 EfficientNMS 插件，EfficientIdxNMS 多了一个 `detection_indices` 节点，用于获取筛选后的索引值，从而确保可以通过索引值获取到对应的掩码系数。这使得在实例分割任务中，能够高效地提取和处理分割掩码，进一步提升模型的推理效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10c64484",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/my_ubuntu/AI_deployment/TRT-TritonServer-Lesson/course_functions/head.py:287: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "/home/my_ubuntu/myenv/lib/python3.10/site-packages/ultralytics/utils/tal.py:369: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  for i, stride in enumerate(strides):\n",
      "[W707 22:16:50.750842367 shape_type_inference.cpp:1995] Warning: The shape inference of TRT::EfficientIdxNMS_TRT type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W707 22:16:50.756378495 shape_type_inference.cpp:1995] Warning: The shape inference of TRT::EfficientIdxNMS_TRT type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W707 22:16:50.757451990 shape_type_inference.cpp:1995] Warning: The shape inference of TRT::EfficientIdxNMS_TRT type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W707 22:16:50.758494058 shape_type_inference.cpp:1995] Warning: The shape inference of TRT::EfficientIdxNMS_TRT type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W707 22:16:50.759438109 shape_type_inference.cpp:1995] Warning: The shape inference of TRT::EfficientIdxNMS_TRT type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "/home/my_ubuntu/myenv/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:5385: UserWarning: Exporting aten::index operator of advanced indexing in opset 16 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxsim\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from course_functions.head import UltralyticsSegment\n",
    "\n",
    "def export_model(model_path: str, output_path: str, batch: int = 1, \n",
    "                 imgsz: tuple = (640, 640), max_boxes: int = 100, \n",
    "                 iou_thres: float = 0.45, conf_thres: float = 0.25, \n",
    "                 opset_version: int = 11) -> None:\n",
    "    \"\"\"\n",
    "    将 YOLO 模型导出为 ONNX 格式，并修改检测头。\n",
    "    \n",
    "    参数：\n",
    "    - model_path: YOLO 模型权重文件的路径。\n",
    "    - output_path: 导出的 ONNX 模型保存路径。\n",
    "    - batch: 模型的批量大小，默认为 1。\n",
    "    - imgsz: 模型输入的图像尺寸，默认为 (640, 640)。\n",
    "    - max_boxes: 每张图片的最大检测数量，默认为 100。\n",
    "    - iou_thres: NMS 的 IoU 阈值，默认为 0.25。\n",
    "    - conf_thres: 检测的置信度阈值，默认为 0.25。\n",
    "    - opset_version: ONNX opset 版本，默认为 11。\n",
    "    \"\"\"\n",
    "    # 加载指定权重的 YOLO 模型并设置为 CPU 模式\n",
    "    model = YOLO(model=model_path, verbose=False).model.to('cpu')\n",
    "    img_h, img_w = imgsz\n",
    "\n",
    "    # 修改 Detect 层的参数\n",
    "    for m in model.modules():\n",
    "        if m.__class__.__name__ == \"Segment\":\n",
    "            m.__class__ = type(\"Segment\", (UltralyticsSegment,), {\n",
    "                \"dynamic\": batch <= 0,  # 是否需要动态批量大小\n",
    "                \"max_det\": max_boxes,  # 每张图片的最大检测数量\n",
    "                \"iou_thres\": iou_thres,  # NMS 的 IoU 阈值\n",
    "                \"conf_thres\": conf_thres,  # 检测的置信度阈值\n",
    "            })\n",
    "            break\n",
    "\n",
    "    # 创建模型的虚拟输入张量\n",
    "    dummy_input = torch.randn(1 if batch <= 0 else batch, 3, *imgsz).to('cpu')\n",
    "    model.eval().float()  # 将模型设置为评估模式，并确保其为浮点精度\n",
    "    # model(dummy_input)  # 使用虚拟输入运行模型，以确保其正确配置\n",
    "\n",
    "    # 将模型导出为 ONNX 格式\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        output_path,\n",
    "        export_params=True,\n",
    "        opset_version=16,\n",
    "        do_constant_folding=True,\n",
    "        input_names=['images'],\n",
    "        output_names=[\"num_dets\", \"det_boxes\", \"det_scores\", \"det_classes\", \"det_masks\"],\n",
    "        dynamic_axes={\n",
    "            \"images\": {0: \"batch\", 2: \"height\", 3: \"width\"},\n",
    "            \"num_dets\": {0: \"batch\"},\n",
    "            \"det_boxes\": {0: \"batch\"},\n",
    "            \"det_scores\": {0: \"batch\"},\n",
    "            \"det_classes\": {0: \"batch\"},\n",
    "            \"det_masks\": {0: \"batch\"},\n",
    "        } if batch <= 0 else None,  # 如果批量大小是动态的，则定义动态轴\n",
    "    )\n",
    "\n",
    "    # 加载导出的 ONNX 模型并进行验证\n",
    "    model_onnx = onnx.load(output_path)\n",
    "    onnx.checker.check_model(model_onnx)\n",
    "\n",
    "    # 则更新输出节点维度\n",
    "    shapes = {\n",
    "        'num_dets': [\"batch\" if batch <= 0 else batch, 1],\n",
    "        'det_boxes': [\"batch\" if batch <= 0 else batch, max_boxes, 4],\n",
    "        'det_scores': [\"batch\" if batch <= 0 else batch, max_boxes],\n",
    "        'det_classes': [\"batch\" if batch <= 0 else batch, max_boxes],\n",
    "        'det_masks': [\"batch\" if batch <= 0 else batch, max_boxes, \"height\" if batch <= 0 else img_h, \"width\" if batch <= 0 else img_w],\n",
    "    }\n",
    "    for node in model_onnx.graph.output:\n",
    "        for idx, dim in enumerate(node.type.tensor_type.shape.dim):\n",
    "            dim.dim_param = str(shapes[node.name][idx])\n",
    "\n",
    "    # 简化 ONNX 模型\n",
    "    model_onnx, check = onnxsim.simplify(model_onnx)\n",
    "    assert check, \"Simplified ONNX model could not be validated\"\n",
    "    onnx.save(model_onnx, output_path)  # 保存简化后的 ONNX 模型\n",
    "\n",
    "# 调用函数导出模型\n",
    "export_model(\"./course_data/models/SEG/yolo11n-seg.pt\", \"./course_data/models/SEG/yolo11n-seg_with_plugin.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ed0e14",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "url, port = netron.start(\"./course_data/models/SEG/yolo11n-seg_with_plugin.onnx\", verbosity=0, browse=False)\n",
    "display(IFrame(f'http://{url}:{port}', width='100%', height='620px'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c89b31",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<b><font color=\"red\">作业：</font></b>对 [Ultralytics-YOLO Segment](https://github.com/ultralytics/ultralytics) 导出集成 EfficientIdxNMS 插件的 ONNX 模型后，相信大家已经摩拳擦掌，准备亲自动手实践了。那么，接下来的挑战是：尝试为[YOLOv5 Segment](https://github.com/ultralytics/yolov5) 导出集成 EfficientIdxNMS 插件的 ONNX 模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab14e02",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>总结</center>\n",
    "\n",
    "本节课程中通过对比 YOLOv5 至 YOLOv11 在分割任务中的结构差异，我们了解了各版本在输入输出格式和分割掩码生成方式上的特点。之后，我们介绍了如何为 YOLO Segmentation 模型注册自定义插件，特别是通过开发 EfficientIdxNMS 插件提升推理效率。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "rise": {
   "enable_chalkboard": true,
   "header": "<img src='https://img.shields.io/badge/Author-laugh12321-0091BD?style=flat-square'>",
   "scroll": true,
   "theme": "simple"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
